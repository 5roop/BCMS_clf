{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import transliterate, is_alpha, load_SET_dataset, load_twitter_dataset, get_N_tokens, LABELS, read_and_split_file\n",
    "import pandas as pd\n",
    "\n",
    "def load_tails():\n",
    "    interim_dir = \"/home/peterr/macocu/taskB/data/interim\"\n",
    "    texts, labels = list(), list()\n",
    "    files = [\"bswac_tail_pp\", \"cnrwac_tail_pp_corrected_2\", \"hrwac_tail_pp\", \"srwac_tail_pp\"]\n",
    "    langs = [\"bs\", \"me\", \"hr\", \"sr\"]\n",
    "\n",
    "    for file, lang in zip(files, langs):\n",
    "        full_path = os.path.join(interim_dir, file)\n",
    "        current_texts = read_and_split_file(full_path)\n",
    "        len_cur_texts = len(current_texts)\n",
    "        texts.extend(current_texts)\n",
    "        labels.extend([lang] * len_cur_texts)\n",
    "\n",
    "    return pd.DataFrame(data={\"text\": texts, \"labels\": labels})\n",
    "\n",
    "train = load_tails()\n",
    "SET = load_SET_dataset().rename(columns={\"language\":\"labels\"})\n",
    "\n",
    "dev_df = SET.loc[SET.split == \"train\", [\"text\", \"labels\"]]\n",
    "test_df = SET.loc[SET.split != \"train\", [\"text\", \"labels\"]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 20000 features per sample; expecting 19293",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-fe48cfaf6f36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_clf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mrezdict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_clf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mrezdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dev\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"SET train\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrezdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-fe48cfaf6f36>\u001b[0m in \u001b[0;36meval_clf\u001b[0;34m(clf, eval_df, vectorizer)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mtest_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_vectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mmacro\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLABELS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"macro\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mmicro\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLABELS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"micro\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0mper\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \"\"\"\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             raise ValueError(\"X has %d features per sample; expecting %d\"\n\u001b[0m\u001b[1;32m    287\u001b[0m                              % (X.shape[1], n_features))\n\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: X has 20000 features per sample; expecting 19293"
     ]
    }
   ],
   "source": [
    "def train_clf(N, train):\n",
    "    from sklearn.svm import LinearSVC\n",
    "    import gc\n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    gc.collect()\n",
    "    clf = LinearSVC(dual=False)\n",
    "    vectorizer = CountVectorizer(lowercase=True, binary=True, ngram_range=(3,3), analyzer=\"char\", max_features=N)\n",
    "    train_vectors = vectorizer.fit_transform(train.text)\n",
    "    train_labels = train.labels\n",
    "    clf.fit(train_vectors.toarray(), train_labels)\n",
    "\n",
    "    return clf, vectorizer\n",
    "\n",
    "def eval_clf(clf, eval_df, vectorizer):\n",
    "    from sklearn.metrics import (\n",
    "        f1_score,\n",
    "        ConfusionMatrixDisplay,\n",
    "        confusion_matrix,\n",
    "        accuracy_score,\n",
    "    )\n",
    "    test_vectors = vectorizer.fit_transform(eval_df.text)\n",
    "    y_true = eval_df.labels\n",
    "    y_pred = clf.predict(test_vectors.toarray())\n",
    "    macro = f1_score(y_true, y_pred, labels=LABELS, average=\"macro\")\n",
    "    micro = f1_score(y_true, y_pred, labels=LABELS, average=\"micro\")\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=LABELS)\n",
    "    returndict = dict(\n",
    "        N=N,\n",
    "        macroF1=macro,\n",
    "        microF1=micro,\n",
    "        accuracy=acc,\n",
    "        cm = cm,\n",
    "\n",
    "    )\n",
    "    return returndict\n",
    "import numpy as np\n",
    "#results = list()\n",
    "for N in [15000, 20000]:\n",
    "    try:\n",
    "        clf, vectorizer = train_clf(N, train)\n",
    "        rezdict = eval_clf(clf, dev_df, vectorizer)\n",
    "        rezdict[\"dev\"] = \"SET train\"\n",
    "        results.append(rezdict)\n",
    "    except MemoryError:\n",
    "        print(\"Failed at\", N, \",  quitting.\")\n",
    "        break\n",
    "    finally:\n",
    "        pd.DataFrame(data=results).to_csv(\"2_part_SETIMES_hyperparams_optimization_3gram.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    |   Unnamed: 0 |     N |    macroF1 |   microF1 |   accuracy | cm                      | dev       |\n",
      "|---:|-------------:|------:|-----------:|----------:|-----------:|:------------------------|:----------|\n",
      "|  0 |            0 |   100 | 0.00183192 | 0.0012205 |  0.0012205 | [[   4    1    3 2548]  | SET train |\n",
      "|    |              |       |            |           |            |  [   1    2    3 2550]  |           |\n",
      "|    |              |       |            |           |            |  [   1    0    3 2258]  |           |\n",
      "|    |              |       |            |           |            |  [   0    0    0    0]] |           |\n",
      "|  1 |            1 |   500 | 0.0799999  | 0.0735015 |  0.0735015 | [[ 413   20  122 2001]  | SET train |\n",
      "|    |              |       |            |           |            |  [ 479   24   95 1958]  |           |\n",
      "|    |              |       |            |           |            |  [ 301    8  105 1848]  |           |\n",
      "|    |              |       |            |           |            |  [   0    0    0    0]] |           |\n",
      "|  2 |            2 |  1000 | 0.160471   | 0.19067   |  0.19067   | [[ 896   66  507 1087]  | SET train |\n",
      "|    |              |       |            |           |            |  [1138   99  354  965]  |           |\n",
      "|    |              |       |            |           |            |  [ 702   81  411 1068]  |           |\n",
      "|    |              |       |            |           |            |  [   0    0    0    0]] |           |\n",
      "|  3 |            3 |  5000 | 0.223974   | 0.304177  |  0.304177  | [[ 634  434 1307  181]  | SET train |\n",
      "|    |              |       |            |           |            |  [ 671  382 1321  182]  |           |\n",
      "|    |              |       |            |           |            |  [ 636  219 1227  180]  |           |\n",
      "|    |              |       |            |           |            |  [   0    0    0    0]] |           |\n",
      "|  4 |            4 | 10000 | 0.179591   | 0.347844  |  0.347844  | [[2259  138  143   16]  | SET train |\n",
      "|    |              |       |            |           |            |  [2182  139  213   22]  |           |\n",
      "|    |              |       |            |           |            |  [1957  129  167    9]  |           |\n",
      "|    |              |       |            |           |            |  [   0    0    0    0]] |           |\n",
      "|  5 |            5 | 15000 | 0.164105   | 0.297261  |  0.297261  | [[ 292   86 2155   23]  | SET train |\n",
      "|    |              |       |            |           |            |  [ 439   73 2009   35]  |           |\n",
      "|    |              |       |            |           |            |  [ 342   53 1827   40]  |           |\n",
      "|    |              |       |            |           |            |  [   0    0    0    0]] |           |\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(pd.read_csv(\"2_part_SETIMES_hyperparams_optimization_3gram.csv\").to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'N': 100,\n",
       "  'macroF1': 0.0018319197539269265,\n",
       "  'microF1': 0.0012205044751830757,\n",
       "  'accuracy': 0.0012205044751830757,\n",
       "  'cm': array([[   4,    1,    3, 2548],\n",
       "         [   1,    2,    3, 2550],\n",
       "         [   1,    0,    3, 2258],\n",
       "         [   0,    0,    0,    0]]),\n",
       "  'dev': 'SET train'},\n",
       " {'N': 500,\n",
       "  'macroF1': 0.07999991948317281,\n",
       "  'microF1': 0.0735014917276919,\n",
       "  'accuracy': 0.0735014917276919,\n",
       "  'cm': array([[ 413,   20,  122, 2001],\n",
       "         [ 479,   24,   95, 1958],\n",
       "         [ 301,    8,  105, 1848],\n",
       "         [   0,    0,    0,    0]]),\n",
       "  'dev': 'SET train'},\n",
       " {'N': 1000,\n",
       "  'macroF1': 0.1604714433193727,\n",
       "  'microF1': 0.19066992134526717,\n",
       "  'accuracy': 0.19066992134526717,\n",
       "  'cm': array([[ 896,   66,  507, 1087],\n",
       "         [1138,   99,  354,  965],\n",
       "         [ 702,   81,  411, 1068],\n",
       "         [   0,    0,    0,    0]]),\n",
       "  'dev': 'SET train'},\n",
       " {'N': 5000,\n",
       "  'macroF1': 0.22397422750275797,\n",
       "  'microF1': 0.3041768375372932,\n",
       "  'accuracy': 0.3041768375372932,\n",
       "  'cm': array([[ 634,  434, 1307,  181],\n",
       "         [ 671,  382, 1321,  182],\n",
       "         [ 636,  219, 1227,  180],\n",
       "         [   0,    0,    0,    0]]),\n",
       "  'dev': 'SET train'},\n",
       " {'N': 10000,\n",
       "  'macroF1': 0.17959066221936085,\n",
       "  'microF1': 0.3478437754271766,\n",
       "  'accuracy': 0.3478437754271766,\n",
       "  'cm': array([[2259,  138,  143,   16],\n",
       "         [2182,  139,  213,   22],\n",
       "         [1957,  129,  167,    9],\n",
       "         [   0,    0,    0,    0]]),\n",
       "  'dev': 'SET train'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7f6f5766036ee03d059e365a942add07f79c17033585e9357ee8157d52fe6bb9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
