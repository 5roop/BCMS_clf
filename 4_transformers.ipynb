{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils import LABELS, load_SET_dataset, load_twitter_dataset, read_and_split_file\n",
    "def load_tails():\n",
    "    interim_dir = \"/home/peterr/macocu/taskB/data/interim\"\n",
    "    texts, labels = list(), list()\n",
    "    files = [\"bswac_tail_pp\", \"cnrwac_tail_pp_corrected_2\", \"hrwac_tail_pp\", \"srwac_tail_pp\"]\n",
    "    langs = [\"bs\", \"me\", \"hr\", \"sr\"]\n",
    "\n",
    "    for file, lang in zip(files, langs):\n",
    "        full_path = os.path.join(interim_dir, file)\n",
    "        current_texts = read_and_split_file(full_path)\n",
    "        len_cur_texts = len(current_texts)\n",
    "        texts.extend(current_texts)\n",
    "        labels.extend([lang] * len_cur_texts)\n",
    "\n",
    "    return pd.DataFrame(data={\"text\": texts, \"labels\": labels})\n",
    "\n",
    "train = load_tails()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SET = load_SET_dataset().rename(columns={\"language\":\"labels\"})\n",
    "SET_dev_df = SET.loc[SET.split == \"train\", [\"text\", \"labels\"]]\n",
    "SET_test_df = SET.loc[SET.split != \"train\", [\"text\", \"labels\"]]\n",
    "\n",
    "tw = load_twitter_dataset().rename(columns={\"language\":\"labels\"})\n",
    "tw[\"text\"] = tw.tweets.apply(lambda l: \" \".join(l))\n",
    "tw_dev_df = tw.loc[tw.split == \"train\", [\"text\", \"labels\"]]\n",
    "tw_test_df = tw.loc[tw.split != \"train\", [\"text\", \"labels\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(N, output_dir=\"outputs/\"):\n",
    "    from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
    "    model_args = ClassificationArgs()\n",
    "    model_args.num_train_epochs = N\n",
    "    model_args.overwrite_output_dir = True\n",
    "    #model_args.output_dir = output_dir\n",
    "    model_args.train_batch_size = 32\n",
    "    model_args.no_cache = True\n",
    "    model_args.no_save = True\n",
    "    model_args.save_steps = -1\n",
    "    model_args.save_model_every_epoch = True,\n",
    "    model_args.max_seq_length = 512\n",
    "    model_args.labels_list = LABELS\n",
    "\n",
    "\n",
    "    model = ClassificationModel(\"electra\", \"classla/bcms-bertic\",\n",
    "                                num_labels = len(LABELS),\n",
    "                                use_cuda = True,\n",
    "                                args = model_args,\n",
    "                                )\n",
    "    model.train_model(train )\n",
    "    return model\n",
    "\n",
    "def eval_model(model, df):\n",
    "    y_true = df.labels\n",
    "    y_pred = model.predict(df.text.tolist())[0]\n",
    "\n",
    "    from sklearn.metrics import (\n",
    "        f1_score,\n",
    "        confusion_matrix,\n",
    "        accuracy_score,\n",
    "    )\n",
    "    y_true = df.labels\n",
    "    y_pred = model.predict(df.text.tolist())[0]\n",
    "    macro = f1_score(y_true, y_pred, labels=LABELS, average=\"macro\")\n",
    "    micro = f1_score(y_true, y_pred, labels=LABELS, average=\"micro\")\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=LABELS)\n",
    "    returndict = dict(\n",
    "        macroF1=macro,\n",
    "        microF1=micro,\n",
    "        CM = cm,\n",
    "         )\n",
    "    return returndict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peterr/anaconda3/lib/python3.8/site-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (1.26.8) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n",
      "Some weights of the model checkpoint at classla/bcms-bertic were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at classla/bcms-bertic and are newly initialized: ['pooler.dense.bias', 'classifier.bias', 'classifier.weight', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "422e55e1446d4d45af8242efcf6dee81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/331725 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9efe827d2c69497a9770873e52d64e86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45fcfdeaeef1451fa6a11632ebedc559",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 1:   0%|          | 0/10367 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peterr/anaconda3/lib/python3.8/site-packages/simpletransformers/classification/classification_model.py:941: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c690d2e9ee2411593ffa047d1bb7c51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/368 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f0c0a129a644c348dbe231dc2b86407",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27f5030bd3d2402db2025a8fa67f521f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/368 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99d084abd337434e91444fa4b319015b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8133b7dca9694bc799b3ebb288b11e0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "123697bed4d14c478e99fb7833a813f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c132d85522534878b9ed73ae0a4ed3dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/246 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a285fe5693694a6997ddb1337f013b2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/31 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2271ba8eb5c4405a8f761e33b67c07be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7374 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a15f3187cd0d423480d3118ed70cbfc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/922 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20a254906fd547abbcaf93acadfdc1f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7374 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "749e2aa7e02e42529ec0d14ff52de947",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/922 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44ae6946847a4f47a217d4eee06694d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a68cb07de650439dad2034dd8c63c4b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/236 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa0eba074ad940139ec0bd969af46e65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1884 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bed2d41c66214044bb27cff2328eff45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/236 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at classla/bcms-bertic were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at classla/bcms-bertic and are newly initialized: ['pooler.dense.bias', 'classifier.bias', 'classifier.weight', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e73197db6b3f41c9b977d645069ac1ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/331725 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8c5ec5ed4a142ca92211a4644a16eff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcf438250f504bbb9ca035edb4f73854",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 2:   0%|          | 0/10367 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = list()\n",
    "for N in [1,2,3]:\n",
    "    model = train_model(N, output_dir=f\"outputs/{N}epochs/\")\n",
    "    \n",
    "    dataset = \"Twitter\"\n",
    "    split = \"dev\"\n",
    "    rezdict = eval_model(model, tw_dev_df)\n",
    "    rezdict[\"dataset\"] = dataset\n",
    "    rezdict[\"split\"] = split\n",
    "    rezdict[\"clf\"] = f\"Bertic {N} epochs\"\n",
    "    results.append(rezdict)\n",
    "    \n",
    "    dataset = \"Twitter\"\n",
    "    split = \"test\"\n",
    "    rezdict = eval_model(model, tw_test_df)\n",
    "    rezdict[\"dataset\"] = dataset\n",
    "    rezdict[\"split\"] = split\n",
    "    rezdict[\"clf\"] = f\"Bertic {N} epochs\"\n",
    "    results.append(rezdict)\n",
    "\n",
    "    dataset = \"SETimes\"\n",
    "    split = \"dev\"\n",
    "    rezdict = eval_model(model, SET_dev_df)\n",
    "    rezdict[\"dataset\"] = dataset\n",
    "    rezdict[\"split\"] = split\n",
    "    rezdict[\"clf\"] = f\"Bertic {N} epochs\"\n",
    "    results.append(rezdict)\n",
    "\n",
    "    dataset = \"SETimes\"\n",
    "    split = \"test\"\n",
    "    rezdict = eval_model(model, SET_test_df)\n",
    "    rezdict[\"dataset\"] = dataset\n",
    "    rezdict[\"split\"] = split\n",
    "    rezdict[\"clf\"] = f\"Bertic {N} epochs\"\n",
    "    results.append(rezdict)\n",
    "    pd.DataFrame(data=results).to_csv(\"results_bertic.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(data=results).to_csv(\"results_bertic.csv\")\n",
    "pd.DataFrame(data=results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7f6f5766036ee03d059e365a942add07f79c17033585e9357ee8157d52fe6bb9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
