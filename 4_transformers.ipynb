{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils import LABELS, load_SET_dataset, load_twitter_dataset, read_and_split_file\n",
    "def load_tails():\n",
    "    interim_dir = \"/home/peterr/macocu/taskB/data/interim\"\n",
    "    texts, labels = list(), list()\n",
    "    files = [\"bswac_tail_pp\", \"cnrwac_tail_pp_corrected_2\", \"hrwac_tail_pp\", \"srwac_tail_pp\"]\n",
    "    langs = [\"bs\", \"me\", \"hr\", \"sr\"]\n",
    "\n",
    "    for file, lang in zip(files, langs):\n",
    "        full_path = os.path.join(interim_dir, file)\n",
    "        current_texts = read_and_split_file(full_path)\n",
    "        len_cur_texts = len(current_texts)\n",
    "        texts.extend(current_texts)\n",
    "        labels.extend([lang] * len_cur_texts)\n",
    "\n",
    "    return pd.DataFrame(data={\"text\": texts, \"labels\": labels})\n",
    "\n",
    "train = load_tails()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SET = load_SET_dataset().rename(columns={\"language\":\"labels\"})\n",
    "SET_dev_df = SET.loc[SET.split == \"train\", [\"text\", \"labels\"]]\n",
    "SET_test_df = SET.loc[SET.split != \"train\", [\"text\", \"labels\"]]\n",
    "\n",
    "tw = load_twitter_dataset().rename(columns={\"language\":\"labels\"})\n",
    "tw[\"text\"] = tw.tweets.apply(lambda l: \" \".join(l))\n",
    "tw_dev_df = tw.loc[tw.split == \"train\", [\"text\", \"labels\"]]\n",
    "tw_test_df = tw.loc[tw.split != \"train\", [\"text\", \"labels\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(N, output_dir=\"outputs/\"):\n",
    "    from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
    "    model_args = ClassificationArgs()\n",
    "    model_args.num_train_epochs = N\n",
    "    #model_args.overwrite_output_dir = True\n",
    "    model_args.output_dir = output_dir\n",
    "    model_args.train_batch_size = 32\n",
    "    #model_args.no_cache = True\n",
    "    #model_args.no_save = True\n",
    "    #model_args.save_steps = -1\n",
    "    model_args.save_model_every_epoch = True,\n",
    "    model_args.max_seq_length = 512\n",
    "    model_args.labels_list = LABELS\n",
    "\n",
    "\n",
    "    model = ClassificationModel(\"electra\", \"classla/bcms-bertic\",\n",
    "                                num_labels = len(LABELS),\n",
    "                                use_cuda = True,\n",
    "                                args = model_args,\n",
    "                                )\n",
    "    model.train_model(train )\n",
    "    return model\n",
    "\n",
    "def eval_model(model, df):\n",
    "    y_true = df.labels\n",
    "    y_pred = model.predict(df.text.tolist())[0]\n",
    "\n",
    "    from sklearn.metrics import (\n",
    "        f1_score,\n",
    "        confusion_matrix,\n",
    "        accuracy_score,\n",
    "    )\n",
    "    y_true = df.labels\n",
    "    y_pred = model.predict(df.text.tolist())[0]\n",
    "    macro = f1_score(y_true, y_pred, labels=LABELS, average=\"macro\")\n",
    "    micro = f1_score(y_true, y_pred, labels=LABELS, average=\"micro\")\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=LABELS)\n",
    "    returndict = dict(\n",
    "        macroF1=macro,\n",
    "        microF1=micro,\n",
    "        CM = cm,\n",
    "         )\n",
    "    return returndict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at classla/bcms-bertic were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at classla/bcms-bertic and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc7cbccceafd443c810791a68e885074",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/331725 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a859d6fb6a44645b9f396566088106d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06827862f68d4c198ed1d1ca73d182a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 0 of 1:   0%|          | 0/10367 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peterr/anaconda3/lib/python3.8/site-packages/simpletransformers/classification/classification_model.py:941: FutureWarning: Non-finite norm encountered in torch.nn.utils.clip_grad_norm_; continuing anyway. Note that the default behavior will change in a future release to error out if a non-finite total norm is encountered. At that point, setting error_if_nonfinite=false will be required to retain the old behavior.\n",
      "  torch.nn.utils.clip_grad_norm_(\n"
     ]
    }
   ],
   "source": [
    "results = list()\n",
    "for N in [1,2,3]:\n",
    "    model = train_model(N, output_dir=f\"outputs/{N}epochs/\")\n",
    "    \n",
    "    dataset = \"Twitter\"\n",
    "    split = \"dev\"\n",
    "    rezdict = eval_model(model, tw_dev_df)\n",
    "    rezdict[\"dataset\"] = dataset\n",
    "    rezdict[\"split\"] = split\n",
    "    rezdict[\"clf\"] = f\"Bertic {N} epochs\"\n",
    "    results.append(rezdict)\n",
    "    \n",
    "    dataset = \"Twitter\"\n",
    "    split = \"test\"\n",
    "    rezdict = eval_model(model, tw_test_df)\n",
    "    rezdict[\"dataset\"] = dataset\n",
    "    rezdict[\"split\"] = split\n",
    "    rezdict[\"clf\"] = f\"Bertic {N} epochs\"\n",
    "    results.append(rezdict)\n",
    "\n",
    "    dataset = \"SETimes\"\n",
    "    split = \"dev\"\n",
    "    rezdict = eval_model(model, SET_dev_df)\n",
    "    rezdict[\"dataset\"] = dataset\n",
    "    rezdict[\"split\"] = split\n",
    "    rezdict[\"clf\"] = f\"Bertic {N} epochs\"\n",
    "    results.append(rezdict)\n",
    "\n",
    "    dataset = \"SETimes\"\n",
    "    split = \"test\"\n",
    "    rezdict = eval_model(model, SET_test_df)\n",
    "    rezdict[\"dataset\"] = dataset\n",
    "    rezdict[\"split\"] = split\n",
    "    rezdict[\"clf\"] = f\"Bertic {N} epochs\"\n",
    "    results.append(rezdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>macroF1</th>\n",
       "      <th>microF1</th>\n",
       "      <th>CM</th>\n",
       "      <th>dataset</th>\n",
       "      <th>split</th>\n",
       "      <th>clf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.042289</td>\n",
       "      <td>0.092391</td>\n",
       "      <td>[[0, 0, 0, 53], [0, 0, 0, 45], [0, 0, 0, 236],...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>dev</td>\n",
       "      <td>Bertic 1 epochs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.041045</td>\n",
       "      <td>0.089431</td>\n",
       "      <td>[[0, 0, 0, 36], [0, 0, 0, 30], [0, 0, 0, 158],...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>test</td>\n",
       "      <td>Bertic 1 epochs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[[0, 0, 0, 2556], [0, 0, 0, 2556], [0, 0, 0, 2...</td>\n",
       "      <td>SETimes</td>\n",
       "      <td>dev</td>\n",
       "      <td>Bertic 1 epochs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[[0, 0, 0, 640], [0, 0, 0, 639], [0, 0, 0, 605...</td>\n",
       "      <td>SETimes</td>\n",
       "      <td>test</td>\n",
       "      <td>Bertic 1 epochs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.132057</td>\n",
       "      <td>0.163043</td>\n",
       "      <td>[[45, 8, 0, 0], [31, 14, 0, 0], [158, 77, 0, 1...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>dev</td>\n",
       "      <td>Bertic 2 epochs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.112981</td>\n",
       "      <td>0.158537</td>\n",
       "      <td>[[31, 5, 0, 0], [22, 8, 0, 0], [102, 56, 0, 0]...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>test</td>\n",
       "      <td>Bertic 2 epochs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.137606</td>\n",
       "      <td>0.329672</td>\n",
       "      <td>[[7, 2549, 0, 0], [1, 2424, 0, 131], [0, 1367,...</td>\n",
       "      <td>SETimes</td>\n",
       "      <td>dev</td>\n",
       "      <td>Bertic 2 epochs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.136172</td>\n",
       "      <td>0.323779</td>\n",
       "      <td>[[1, 639, 0, 0], [1, 609, 0, 29], [0, 362, 0, ...</td>\n",
       "      <td>SETimes</td>\n",
       "      <td>test</td>\n",
       "      <td>Bertic 2 epochs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.423726</td>\n",
       "      <td>0.611413</td>\n",
       "      <td>[[14, 39, 0, 0], [4, 29, 7, 5], [0, 51, 178, 7...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>dev</td>\n",
       "      <td>Bertic 3 epochs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.375476</td>\n",
       "      <td>0.597561</td>\n",
       "      <td>[[7, 29, 0, 0], [1, 24, 3, 2], [0, 33, 116, 9]...</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>test</td>\n",
       "      <td>Bertic 3 epochs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.047503</td>\n",
       "      <td>0.056414</td>\n",
       "      <td>[[0, 1780, 0, 776], [0, 385, 8, 2163], [0, 1, ...</td>\n",
       "      <td>SETimes</td>\n",
       "      <td>dev</td>\n",
       "      <td>Bertic 3 epochs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.042100</td>\n",
       "      <td>0.049894</td>\n",
       "      <td>[[0, 443, 0, 197], [0, 89, 0, 550], [0, 0, 5, ...</td>\n",
       "      <td>SETimes</td>\n",
       "      <td>test</td>\n",
       "      <td>Bertic 3 epochs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     macroF1   microF1                                                 CM  \\\n",
       "0   0.042289  0.092391  [[0, 0, 0, 53], [0, 0, 0, 45], [0, 0, 0, 236],...   \n",
       "1   0.041045  0.089431  [[0, 0, 0, 36], [0, 0, 0, 30], [0, 0, 0, 158],...   \n",
       "2   0.000000  0.000000  [[0, 0, 0, 2556], [0, 0, 0, 2556], [0, 0, 0, 2...   \n",
       "3   0.000000  0.000000  [[0, 0, 0, 640], [0, 0, 0, 639], [0, 0, 0, 605...   \n",
       "4   0.132057  0.163043  [[45, 8, 0, 0], [31, 14, 0, 0], [158, 77, 0, 1...   \n",
       "5   0.112981  0.158537  [[31, 5, 0, 0], [22, 8, 0, 0], [102, 56, 0, 0]...   \n",
       "6   0.137606  0.329672  [[7, 2549, 0, 0], [1, 2424, 0, 131], [0, 1367,...   \n",
       "7   0.136172  0.323779  [[1, 639, 0, 0], [1, 609, 0, 29], [0, 362, 0, ...   \n",
       "8   0.423726  0.611413  [[14, 39, 0, 0], [4, 29, 7, 5], [0, 51, 178, 7...   \n",
       "9   0.375476  0.597561  [[7, 29, 0, 0], [1, 24, 3, 2], [0, 33, 116, 9]...   \n",
       "10  0.047503  0.056414  [[0, 1780, 0, 776], [0, 385, 8, 2163], [0, 1, ...   \n",
       "11  0.042100  0.049894  [[0, 443, 0, 197], [0, 89, 0, 550], [0, 0, 5, ...   \n",
       "\n",
       "    dataset split              clf  \n",
       "0   Twitter   dev  Bertic 1 epochs  \n",
       "1   Twitter  test  Bertic 1 epochs  \n",
       "2   SETimes   dev  Bertic 1 epochs  \n",
       "3   SETimes  test  Bertic 1 epochs  \n",
       "4   Twitter   dev  Bertic 2 epochs  \n",
       "5   Twitter  test  Bertic 2 epochs  \n",
       "6   SETimes   dev  Bertic 2 epochs  \n",
       "7   SETimes  test  Bertic 2 epochs  \n",
       "8   Twitter   dev  Bertic 3 epochs  \n",
       "9   Twitter  test  Bertic 3 epochs  \n",
       "10  SETimes   dev  Bertic 3 epochs  \n",
       "11  SETimes  test  Bertic 3 epochs  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data=results).to_csv(\"results_bertic.csv\")\n",
    "pd.DataFrame(data=results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7f6f5766036ee03d059e365a942add07f79c17033585e9357ee8157d52fe6bb9"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
